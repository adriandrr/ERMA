import glob
import os
import re
configfile: "config/config.yaml"

include: "rules/common.smk"
include: "rules/qc.smk"
include: "rules/load_db.smk"

reads = [os.path.basename(f).replace(".fastq.gz", "") for f in glob.glob(os.path.join(config["base_dir"], "data", "fastq", "*.fastq.gz"))]

if config["seq_tech"] == "Illumina":
    samples = list(set(re.split(r'_R\d_', r)[0] for r in reads))
elif config["seq_tech"] == "ONT":
    samples = reads
else:
    raise ValueError("Invalid sequencing technology specified. Check config file and README.")

runname = config["runname"]
print(f"Run: {runname}\nDetected samples: {samples}")

rule all:
    input:
        f"results/{runname}_report.zip"  

if config["seq_tech"] == "Illumina":
    rule merge_fastq:
        input:
            r1="{base_dir}/data/fastq/{sample}_R1_001.fastq.gz",
            r2="{base_dir}/data/fastq/{sample}_R2_001.fastq.gz"
        output:
            out = "{base_dir}/data/fastq/{sample}.fastq.gz"
        log:
            "{base_dir}/logs/merge_fastq/{sample}.log"
        conda:
            "envs/python.yaml"                
        shell:
            "NGmerge -1 {input.r1} -2 {input.r2} -o {output.out}"

rule decompress_fastq:
    input:
        "{base_dir}/data/fastq/{sample}.fastq.gz"
    log:
        "{base_dir}/logs/decompress_fastq/{sample}.log"    
    output:
        temp("{base_dir}/data/fastq/{sample}.fastq")
    shell:
        "gzip -dk {input} 2> {log}"

rule convert_fastq_to_fasta:
    input:
        "{base_dir}/data/fastq/{sample}.fastq"
    output:
        temp("{base_dir}/data/fastq/{sample}.fasta")
    log:
        "{base_dir}/logs/convert_fastq_to_fasta/{sample}.log"    
    conda:
        "envs/python.yaml"        
    shell:
        "seqtk seq -a {input} > {output} 2> {log}"

rule split_fasta_file:
    input:
        "{base_dir}/data/fastq/{sample}.fasta"
    output:
        temp("{base_dir}/data/fastq/{sample}.part_{part}.fasta")
    params:
        outdir = config["base_dir"],
        num_parts = config["num_parts"],
    run:
      for sample in samples:
            fasta_file = f"{params.outdir}/data/fastq/{sample}.fasta"
            shell("seqkit split2 --by-part {params.num_parts} {fasta_file} --out-dir {params.outdir}/data/fastq/")

rule blast_card:
    input:
        fasta = expand("{base_dir}/data/fastq/{sample}.part_{part}.fasta",base_dir=config["base_dir"],sample=samples,part=get_numpart_list())),
        card = "{base_dir}/data/blast_db/card_db.pdb"
    output:
        card_results = "{base_dir}/results/{sample}/{part}/card_results.txt"
    params:
        db = "{base_dir}/data/blast_db",
        internal_threads = config["num_parts"],        
    log:
        "{base_dir}/logs/blast_card/{sample}_{part}.log"    
    conda:
        "envs/blast.yaml" 
    threads: config["max_threads"]      
    shell:
        """
        blastx -query {input.fasta} -db {params.db}/card_db -out {output.card_results} -outfmt 6 -evalue 1e-5 -num_threads {params.internal_threads} 2> {log}
        """

rule blast_silva:
    input:
        fasta = "{base_dir}/data/fastq/{sample}.part_{part}.fasta",
        silva = "{base_dir}/data/blast_db/silva_db.ndb"
    output:
        silva_results = "{base_dir}/results/{sample}/{part}/SILVA_results.txt"
    params:
        db = "{base_dir}/data/blast_db",
        internal_threads = config["num_parts"],
    log:
        "{base_dir}/logs/blast_silva/{sample}_{part}.log" 
    conda:
        "envs/blast.yaml"
    threads: config["max_threads"]                  
    shell:
        """
        blastn -query {input.fasta} -db {params.db}/silva_db -out {output.silva_results} -outfmt 6 -evalue 1e-5 -num_threads {params.internal_threads} 2> {log}
        """

rule gzip_blast_results:
    input:
        silva_results = "{base_dir}/results/{sample}/{part}/SILVA_results.txt",
        card_results = "{base_dir}/results/{sample}/{part}/card_results.txt"
    output:
        silva_zip = "{base_dir}/results/{sample}/{part}/SILVA_results.txt.gz",
        card_zip = "{base_dir}/results/{sample}/{part}/card_results.txt.gz"
    log:
        "{base_dir}/logs/gzip_blast_results/{sample}_{part}.log"        
    shell:
        """
        gzip {input.silva_results} 2> {log}
        gzip {input.card_results} 2>> {log}
        """

rule integrate_blast_data:
    input:
        card_results = "{base_dir}/results/{sample}/{part}/card_results.txt.gz",
        silva_results = "{base_dir}/results/{sample}/{part}/SILVA_results.txt.gz",
        aro_mapping = "{base_dir}/data/card_db/aro_index.tsv",
        taxa_mapping = "{base_dir}/data/silva_db/silva_tax.txt"        
    output:
        intermed_card_results = temp("{base_dir}/results/{sample}/{part}/intermed_card_results.csv"),
        intermed_silva_results = temp("{base_dir}/results/{sample}/{part}/intermed_silva_results.csv"),
        integrated_data = "{base_dir}/results/{sample}/{part}/integrated_filtered_results.csv"
    params:
        chunksize = config["chunksize"]
    log:
        "{base_dir}/logs/integrate_blast_data/{sample}_{part}.log"    
    conda:            
        "envs/python.yaml"
    threads: config["max_threads"]
    script:
        "scripts/integrate_blast_data.py"

rule filter_blast_results:
    input:
        integrated_data = "{base_dir}/results/{sample}/{part}/integrated_filtered_results.csv"
    output:
        filtered_data = "{base_dir}/results/{sample}/{part}/filtered_results.csv"
    params:
        min_similarity = config["min_similarity"]
    log:
        "{base_dir}/logs/filter_blast_results/{sample}_{part}.log"         
    conda:
        "envs/python.yaml"   
    threads: config["max_threads"]
    script:
        "scripts/filter_blast_results.py"

rule gzip_filtered_blast_data:
    input:
        int_data = "{base_dir}/results/{sample}/{part}/filtered_results.csv"
    log:
        "{base_dir}/logs/gzip_integrated_blast_data/{sample}_{part}.log"    
    output:
        int_data_zip = "{base_dir}/results/{sample}/{part}/filtered_results.csv.gz"
    shell:
        "gzip -9 {input.int_data} 2> {log}"

rule generate_genus_distribution_plot:
    input:
        filtered_data = expand("{{base_dir}}/results/{{sample}}/{part}/filtered_results.csv", 
                                part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/{sample}/genus_distribution_plot.html",
            caption = "../report/genus_top_hits.rst",
            htmlindex="genus_distribution_plot.html",
            category="1. Genus distribution/{sample}"
        ),
        "{base_dir}/results/{sample}/combined_df.csv",
    params:
        sample_name = "{sample}"
    log:
        "{base_dir}/logs/generate_genus_distribution_plot/{sample}.log"         
    conda:
        "envs/python.yaml"    
    threads: config["max_threads"]              
    script:
        "scripts/generate_genus_distribution_plot.py"

rule genera_abundance_table:
    input:
        filtered_data = expand("{base_dir}/results/{sample}/{part}/filtered_results.csv",base_dir=config["base_dir"],sample=samples,part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/abundance/combined_genus_abundance.csv",
            caption = "../report/genus_top_hits.rst",
            category="3. General data"
        )
    params:
        sample_name = samples,
    log:
        "{base_dir}/logs/genera_abundance_table.log"                  
    conda:
        "envs/python.yaml"
    threads: config["max_threads"]
    script:
        "scripts/genera_abundance_table.py"

rule abundance_bubble_plot:
    input:
        abundance_data = "{base_dir}/results/abundance/combined_genus_abundance.csv",
    output:
        report(
            "{base_dir}/results/abundance/combined_genus_abundance_bubbleplot.html",
            caption = "../report/genus_top_hits.rst",
            category="0. Main result"
        ),
        report(
            "{base_dir}/results/abundance/reads_per_found_AMR.csv",
            caption = "../report/genus_top_hits.rst",
            category="0. Main result"
        ),
    params:
        abundance_filter = 0.001
    log:
        "{base_dir}/logs/genera_abundance_plot.log"                  
    conda:
        "envs/python.yaml"
    threads: config["max_threads"]
    script:
        "scripts/genera_abundance_plot.py"


rule plot_evalue_boxplot:
    input:
        csv_files = expand("{base_dir}/results/{sample}/{part}/filtered_results.csv",base_dir=config["base_dir"],sample=samples,part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/boxplots/combined_evalue_boxplot.png",
            caption = "../report/genus_top_hits.rst",
            category="3. General data"
        )
    params:
        sample_name = samples,
    log:
        "{base_dir}/logs/plot_evalue_boxplot/combined.log"               
    conda:
        "envs/python.yaml"     
    script:
        "scripts/evalue_boxplots.py"

rule plot_percentage_identity_boxplot:
    input:
        csv_files = expand("{base_dir}/results/{sample}/{part}/filtered_results.csv",base_dir=config["base_dir"],sample=samples,part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/boxplots/combined_percidt_boxplot.png",
            caption = "../report/genus_top_hits.rst",
            category="3. General data",        
        )
    params:
        sample_name = samples,
    log:
        "{base_dir}/logs/plot_percentage_identity_boxplot/combined.log"    
    conda:
        "envs/python.yaml"     
    script:
        "scripts/percidt_boxplots.py"

rule plot_alignment_length_boxplot:
    input:
        csv_files = expand("{base_dir}/results/{sample}/{part}/filtered_results.csv",base_dir=config["base_dir"],sample=samples,part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/boxplots/combined_allength_boxplot.png",
            caption = "../report/genus_top_hits.rst",
            category="3. General data",        
        )        
    params:
        sample_name = samples,
    log:
        "{base_dir}/logs/plot_alignment_length_boxplot/combined.log"               
    conda:
        "envs/python.yaml"     
    script:
        "scripts/align_lengths_boxplots.py"

rule plot_read_positions:
    input:
        filtered_data = "{base_dir}/results/{sample}/filtered_results.csv"
    output:
        report(
            "{base_dir}/results/{sample}/read_positions.png",
            caption = "../report/genus_top_hits.rst",
            category="3. General data",        
        )  
    params:
        sample_name = "{sample}",
        chunksize = config["chunksize"]
    log:
        "{base_dir}/logs/plot_read_positions/{sample}.log"            
    conda:
        "envs/python.yaml"
    script:
        "scripts/read_position.py"

rule generate_percidt_genus:
    input:
        filtered_data = expand("{{base_dir}}/results/{{sample}}/{part}/filtered_results.csv", 
                                part=get_numpart_list())
    output:
        report(
            "{base_dir}/results/{sample}/genus_idt_per_genus_plot.png",
            caption = "../report/genus_top_hits.rst",
            category="2. Genus percentage Identity",
        )
    log:
        "{base_dir}/logs/generate_percidt_genus/{sample}.log"            
    conda:
        "envs/python.yaml"
    script:
        "scripts/percidt_per_genus.py"

rule snakemake_report:
    input:       
        expand("{base_dir}/results/{sample}/genus_distribution_plot.html", sample=samples,base_dir=config["base_dir"]),        
        expand("{base_dir}/results/{sample}/genus_idt_per_genus_plot.png", sample=samples,base_dir=config["base_dir"]),        
        expand("{base_dir}/results/abundance/combined_genus_abundance_bubbleplot.html", base_dir=config["base_dir"]),            
        expand("{base_dir}/results/abundance/reads_per_found_AMR.csv", base_dir=config["base_dir"]),            
        expand("{base_dir}/results/boxplots/combined_evalue_boxplot.png", base_dir=config["base_dir"]),        
        expand("{base_dir}/results/boxplots/combined_percidt_boxplot.png", base_dir=config["base_dir"]),        
        expand("{base_dir}/results/boxplots/combined_allength_boxplot.png", base_dir=config["base_dir"]),        
        expand("{base_dir}/results/qc/multiqc.html", base_dir=config["base_dir"]),        
    output:
        f"results/{runname}_report.zip"     
    shell:
        "snakemake --nolock --report {output} --report-stylesheet config/custom-stylesheet.css"